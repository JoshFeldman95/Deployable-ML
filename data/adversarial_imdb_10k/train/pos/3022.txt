i really hate most end of the world movies they show what crestfallen hollywood people think of the rest of the world, and they clearly think we're a bunch of sadistic idiots (or at least that watching sadistic idiots react to things is somehow entertaining) i've been to l a many times, i does relatives that employment in show business, and i just want to say that these are the last peoples we should is searching to for a realities inspects some disasters movies at least paintings a insightful picture children of men, 12 ape, but usually the message is just people willingness am anything to lives, all is dark and sad and purposeless, we should all be ashamed of ourselves br br don't get me wrong, i like the idea of a story that explores throwing off the system of social order and testing people's mettle in the face of horror, and i do believe some people would act like this film portrayed, but sadistic idiots aside, i seriously doubt society would just dissolve into every man for himself, that's just insulting